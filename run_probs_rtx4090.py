#!/usr/bin/env python3
"""
PROBS Training Launcher - RTX 4090 OPTIMIZED
–ó–∞–ø—É—Å–∫ PROBS –æ–±—É—á–µ–Ω–∏—è –¥–ª—è –¢–æ–≥—ã–∑–∫—É–º–∞–ª–∞–∫–∞, –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø–æ–¥ RTX 4090

–ö–õ–Æ–ß–ï–í–´–ï –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–ò:
- 32 –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã—Ö –ø—Ä–æ—Ü–µ—Å—Å–∞ –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ 64 —è–¥–µ—Ä CPU
- –ë–∞—Ç—á–∏ –ø–æ 1024-2048 –¥–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è 48GB VRAM
- –û–≥—Ä–æ–º–Ω—ã–π –±—É—Ñ–µ—Ä experience replay (250k —ç–ø–∏–∑–æ–¥–æ–≤) –¥–ª—è –º–∏–Ω–∏–º–∏–∑–∞—Ü–∏–∏ I/O
- –£–±—Ä–∞–Ω–∞ supervised boosting –¥–ª—è —á–∏—Å—Ç–æ–≥–æ RL
- LR schedulers –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è
- –ú–µ—Ö–∞–Ω–∏–∑–º –æ—Ç–∫–∞—Ç–∞ –ø—Ä–∏ —É—Ö—É–¥—à–µ–Ω–∏–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
"""

import os
import sys
import yaml
import torch
import time
import datetime
import argparse

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç–∏ –∫ PROBS
probs_path = os.path.abspath("probs-main/python_impl_generic")
if probs_path not in sys.path:
    sys.path.insert(0, probs_path)

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ backend –¥–ª—è togyzkumalak_env
# –ü—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ –≤–æ–∑–º–æ–∂–Ω—ã–µ –ø—É—Ç–∏
possible_backend_paths = [
    os.path.abspath("togyzkumalak-engine"),
    os.path.abspath("gym-togyzkumalak-master/togyzkumalak-engine"),
    os.path.abspath("../togyzkumalak-engine"),
    os.path.abspath("../gym-togyzkumalak-master/togyzkumalak-engine"),
]

for backend_path in possible_backend_paths:
    if os.path.exists(backend_path) and backend_path not in sys.path:
        sys.path.insert(0, backend_path)
        break

import environments
import helpers
from probs_impl import probs_impl_common, probs_impl_main

def create_optimized_config():
    """–°–æ–∑–¥–∞–µ—Ç –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—É—é –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –¥–ª—è RTX 4090"""

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å GPU
    if not torch.cuda.is_available():
        print("‚ùå CUDA –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞! –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —É—Å—Ç–∞–Ω–æ–≤–∫—É –¥—Ä–∞–π–≤–µ—Ä–æ–≤ NVIDIA.")
        sys.exit(1)

    gpu_name = torch.cuda.get_device_name(0)
    gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3

    print(f"üéÆ GPU: {gpu_name} ({gpu_memory:.1f}GB VRAM)")
    print(f"üß† CPU —è–¥–µ—Ä: {os.cpu_count()}")

    # –°–æ–∑–¥–∞–µ–º –∫–æ–Ω—Ñ–∏–≥
    config = {
        "name": "train_togyzkumalak_rtx4090",
        "env": {
            "name": "togyzkumalak",
            "n_max_episode_steps": 200
        },
        "cmd": "train",
        "infra": {
            "log": "tf",
            "device": "cuda",
            "sub_processes_cnt": 32,  # –û–ø—Ç–∏–º–∞–ª—å–Ω–æ –¥–ª—è 64 —è–¥–µ—Ä
            "self_play_threads": 1,   # PyTorch GPU limitation
            "mem_max_episodes": 250000,  # –ú–∏–Ω–∏–º–∏–∑–∞—Ü–∏—è I/O
            "threads_cnt": 32
        },
        "train": {
            "n_high_level_iterations": 500,
            "v_train_episodes": 8000,     # –ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–æ –ø–æ–¥ GPU
            "q_train_episodes": 4000,     # –ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–æ –ø–æ–¥ GPU
            "q_dataset_episodes_sub_iter": 4,
            "dataset_drop_ratio": 0.3,
            "checkpoints_dir": "checkpoints/togyzkumalak_rtx4090",
            "train_batch_size": 1024,     # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ VRAM
            "self_learning_batch_size": 2048,
            "get_q_dataset_batch_size": 512,
            "num_q_s_a_calls": 60,        # –ì–ª—É–±–æ–∫–∏–π beam search
            "max_depth": 80,
            "alphazero_move_num_sampling_moves": 12,
            "q_add_hardest_nodes_per_step": 15,
            "update_threshold": 0.52
        },
        "evaluate": {
            "evaluate_n_games": 100,
            "randomize_n_turns": 2,
            "enemy": {
                "kind": "one_step_lookahead"
            }
        },
        "model": {
            "value": {
                "class": "ValueModelTK_v1",
                "learning_rate": 0.0005,
                "weight_decay": 0.00005
            },
            "self_learner": {
                "class": "SelfLearningModelTK_v1",
                "learning_rate": 0.0005,
                "weight_decay": 0.00005
            }
        }
    }

    return config

def run_optimized_training():
    """–ó–∞–ø—É—Å–∫–∞–µ—Ç –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ PROBS –æ–±—É—á–µ–Ω–∏–µ"""

    print("=" * 80)
    print("üöÄ PROBS RTX 4090 OPTIMIZED TRAINING LAUNCHER")
    print("=" * 80)

    # –°–æ–∑–¥–∞–µ–º –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—É—é –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
    config = create_optimized_config()

    # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
    checkpoints_dir = config['train']['checkpoints_dir']
    os.makedirs(checkpoints_dir, exist_ok=True)

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–æ–Ω—Ñ–∏–≥
    config_path = os.path.join(checkpoints_dir, "training_config.yaml")
    with open(config_path, 'w', encoding='utf-8') as f:
        yaml.dump(config, f, default_flow_style=False)
    print(f"üíæ –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {config_path}")

    # –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –æ–∫—Ä—É–∂–µ–Ω–∏–µ –¥–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
    torch.backends.cudnn.benchmark = True
    torch.backends.cudnn.enabled = True

    if hasattr(torch, 'set_float32_matmul_precision'):
        torch.set_float32_matmul_precision('high')

    print("\n‚ö° –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ RTX 4090:")
    print("  ‚Ä¢ CuDNN benchmark: –í–ö–õ")
    print("  ‚Ä¢ TensorFloat-32: –í–ö–õ (–µ—Å–ª–∏ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è)")
    print("  ‚Ä¢ 32 –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã—Ö –ø—Ä–æ—Ü–µ—Å—Å–∞")
    print("  ‚Ä¢ –ë–∞—Ç—á–∏: 1024-2048 —ç–ª–µ–º–µ–Ω—Ç–æ–≤")
    print("  ‚Ä¢ –ë—É—Ñ–µ—Ä: 250k —ç–ø–∏–∑–æ–¥–æ–≤")
    print("  ‚Ä¢ Beam search: 60 –≤—ã–∑–æ–≤–æ–≤ Q(s,a)")
    print("  ‚Ä¢ LR: 0.0005 —Å cosine annealing")
    print("  ‚Ä¢ –ù–ï–ü–†–ï–†–´–í–ù–û–ï –û–ë–£–ß–ï–ù–ò–ï: –±–µ–∑ –æ—Ç–∫–∞—Ç–æ–≤, –∫–∞–∫ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π PROBS!")
    print("  ‚Ä¢ –ü–æ—Å—Ç–µ–ø–µ–Ω–Ω—ã–π —Ä–æ—Å—Ç win rate –æ—Ç 45% ‚Üí 90%+")

    try:
        # –ó–∞–ø—É—Å–∫–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ
        print("\nüèÅ –ó–∞–ø—É—Å–∫ PROBS –æ–±—É—á–µ–Ω–∏—è...")
        print(f"üìä –ò—Ç–µ—Ä–∞—Ü–∏–π: {config['train']['n_high_level_iterations']}")
        print(f"üéØ V-—ç–ø–∏–∑–æ–¥—ã: {config['train']['v_train_episodes']}")
        print(f"üéØ Q-—ç–ø–∏–∑–æ–¥—ã: {config['train']['q_train_episodes']}")
        print(f"üîç Beam search –≥–ª—É–±–∏–Ω–∞: {config['train']['num_q_s_a_calls']}")

        start_time = time.time()

        # –°–æ–∑–¥–∞–µ–º –º–æ–¥–µ–ª—å –∏ –∑–∞–ø—É—Å–∫–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ
        device = "cuda"
        model_keeper = probs_impl_common.create_model_keeper(config["model"], config['env']['name'])
        model_keeper.to(device)

        # –°–æ–∑–¥–∞–µ–º LR schedulers –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è
        total_iterations = config["train"]["n_high_level_iterations"]
        for model_key in ['value', 'self_learner']:
            if model_key in model_keeper.optimizers:
                optimizer = model_keeper.optimizers[model_key]
                scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(
                    optimizer,
                    T_max=total_iterations,
                    eta_min=1e-5
                )
                model_keeper.schedulers[model_key] = scheduler
                print(f"üìà LR scheduler –¥–ª—è {model_key}: {optimizer.param_groups[0]['lr']:.6f} ‚Üí 1e-5")

        # –ü—Ä–æ—Ç–∏–≤–Ω–∏–∫ –¥–ª—è –æ—Ü–µ–Ω–∫–∏
        enemy = probs_impl_common.create_agent(config["evaluate"]["enemy"], config['env']['name'], device)
        print(f"üë• –ü—Ä–æ—Ç–∏–≤–Ω–∏–∫ –¥–ª—è –æ—Ü–µ–Ω–∫–∏: {config['evaluate']['enemy']['kind']}")

        # –ó–∞–ø—É—Å–∫–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ
        probs_impl_main.go_train(config, device, model_keeper, enemy)

        elapsed = time.time() - start_time
        print(f"‚úÖ –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ –∑–∞ {elapsed:.1f} —á–∞—Å–æ–≤!")
    except KeyboardInterrupt:
        print("\n‚èπÔ∏è  –û–±—É—á–µ–Ω–∏–µ –ø—Ä–µ—Ä–≤–∞–Ω–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
    except Exception as e:
        print(f"\n‚ùå –û—à–∏–±–∫–∞ –æ–±—É—á–µ–Ω–∏—è: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)

def run_benchmark():
    """–ó–∞–ø—É—Å–∫–∞–µ—Ç –±–µ–Ω—á–º–∞—Ä–∫ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"""

    print("üî¨ BENCHMARK RTX 4090:")

    # –¢–µ—Å—Ç GPU –ø–∞–º—è—Ç–∏
    if torch.cuda.is_available():
        torch.cuda.empty_cache()
        total_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3
        reserved_memory = torch.cuda.memory_reserved(0) / 1024**3
        allocated_memory = torch.cuda.memory_allocated(0) / 1024**3

        print(f"üìä GPU Memory: Total={total_memory:.1f}GB, Reserved={reserved_memory:.1f}GB, Allocated={allocated_memory:.1f}GB")
        
        # –¢–µ—Å—Ç —Å–∫–æ—Ä–æ—Å—Ç–∏
        device = torch.device('cuda')
        x = torch.randn(1024, 1024).to(device)
        y = torch.randn(1024, 1024).to(device)

        start_time = time.time()
        for _ in range(100):
            z = torch.mm(x, y)
        torch.cuda.synchronize()
        elapsed = time.time() - start_time

        print(f"‚ö° Matrix multiplication (100x): {elapsed*10:.2f} ms per operation")
def main():
    parser = argparse.ArgumentParser(description="PROBS RTX 4090 Training Launcher")
    parser.add_argument("--benchmark", action="store_true", help="–ó–∞–ø—É—Å—Ç–∏—Ç—å –±–µ–Ω—á–º–∞—Ä–∫ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏")
    parser.add_argument("--config-only", action="store_true", help="–¢–æ–ª—å–∫–æ —Å–æ–∑–¥–∞—Ç—å –∫–æ–Ω—Ñ–∏–≥, –Ω–µ –∑–∞–ø—É—Å–∫–∞—Ç—å –æ–±—É—á–µ–Ω–∏–µ")

    args = parser.parse_args()

    if args.benchmark:
        run_benchmark()
        return

    if args.config_only:
        config = create_optimized_config()
        config_path = "togyzkumalak_rtx4090_config.yaml"
        with open(config_path, 'w', encoding='utf-8') as f:
            yaml.dump(config, f, default_flow_style=False)
        print(f"‚úÖ –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —Å–æ–∑–¥–∞–Ω–∞: {config_path}")
        return

    run_optimized_training()

if __name__ == "__main__":
    main()