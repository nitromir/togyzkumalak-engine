#!/usr/bin/env python3
"""
–ó–∞–ø—É—Å–∫ AlphaZero training –Ω–∞–ø—Ä—è–º—É—é –∏–∑ —Ç–µ—Ä–º–∏–Ω–∞–ª–∞ (–±–µ–∑ UI).
–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–æ –¥–ª—è multi-GPU —Å–∏—Å—Ç–µ–º—ã (4x GPU, 128 —è–¥–µ—Ä).
"""

import os
import sys
import json
import time
import signal
import subprocess

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ backend
backend_dir = os.path.abspath(os.path.join(os.path.dirname(__file__), '..', 'backend'))
if backend_dir not in sys.path:
    sys.path.insert(0, backend_dir)

from task_manager import AlphaZeroTaskManager

# –ì–ª–æ–±–∞–ª—å–Ω–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è –¥–ª—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∏
stop_requested = False

def signal_handler(sig, frame):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ —Å–∏–≥–Ω–∞–ª–∞ –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–π –æ—Å—Ç–∞–Ω–æ–≤–∫–∏."""
    global stop_requested
    print("\n\n‚ö†Ô∏è  –ü–æ–ª—É—á–µ–Ω —Å–∏–≥–Ω–∞–ª –æ—Å—Ç–∞–Ω–æ–≤–∫–∏. –ó–∞–≤–µ—Ä—à–∞—é –æ–±—É—á–µ–Ω–∏–µ –ø–æ—Å–ª–µ —Ç–µ–∫—É—â–µ–π –∏—Ç–µ—Ä–∞—Ü–∏–∏...")
    stop_requested = True

# –†–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–µ–º –æ–±—Ä–∞–±–æ—Ç—á–∏–∫ —Å–∏–≥–Ω–∞–ª–æ–≤
signal.signal(signal.SIGINT, signal_handler)
signal.signal(signal.SIGTERM, signal_handler)

def get_gpu_count():
    """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö GPU."""
    try:
        result = subprocess.run(['nvidia-smi', '--list-gpus'], capture_output=True, text=True, timeout=5)
        if result.returncode == 0:
            return len(result.stdout.strip().split('\n'))
    except:
        pass
    return 0

def get_cpu_count():
    """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ CPU —è–¥–µ—Ä."""
    return os.cpu_count() or 1

def main():
    print("=" * 70)
    print("  ALPHAZERO TRAINING - –ü–†–Ø–ú–û–ô –ó–ê–ü–£–°–ö")
    print("=" * 70)
    print()
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∂–µ–ª–µ–∑–æ
    num_gpus = get_gpu_count()
    num_cpus = get_cpu_count()
    
    print(f"üîß –û–±–Ω–∞—Ä—É–∂–µ–Ω–æ –∂–µ–ª–µ–∑–∞:")
    print(f"   GPU: {num_gpus}")
    print(f"   CPU —è–¥–µ—Ä: {num_cpus}")
    print()
    
    # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –¥–ª—è multi-GPU —Å–∏—Å—Ç–µ–º—ã (4x GPU, 128 —è–¥–µ—Ä)
    # –û—Å–Ω–æ–≤–∞–Ω–æ –Ω–∞ get_optimal_config –∏–∑ alphazero_trainer.py (—Å—Ç—Ä–æ–∫–∏ 2316-2398)
    if num_gpus >= 4:
        # Medium setup (4-7 GPUs) - –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–æ –¥–ª—è 4x RTX 3090/4090
        config = {
            'iterations': 200,
            'games_per_iteration': 128,      # 32 –∏–≥—Ä—ã –Ω–∞ GPU
            'mcts_simulations': 60,          # –•–æ—Ä–æ—à–∞—è –≥–ª—É–±–∏–Ω–∞ –¥–ª—è 4 GPU
            'batch_size': 1024,              # –ë–æ–ª—å—à–æ–π –±–∞—Ç—á –¥–ª—è GPU
            'epochs': 8,
            'lr': 0.001,
            'hidden_size': 256,
            'arena_compare': 20,              # –ë—ã—Å—Ç—Ä–∞—è –æ—Ü–µ–Ω–∫–∞
            'use_bootstrap': True,
            'use_multiprocessing': True,     # –ö–†–ò–¢–ò–ß–ù–û: –≤–∫–ª—é—á–∏—Ç—å multiprocessing
            'num_parallel_games': min(64, num_gpus * 4),  # 16 –¥–ª—è 4 GPU
            'num_workers': min(num_cpus - 2, num_gpus * 10),  # 40 –¥–ª—è 4 GPU, 128 —è–¥–µ—Ä
            'save_every_n_iters': 2,
            'update_threshold': 0.55
        }
    elif num_gpus >= 2:
        # Small setup (2-3 GPUs)
        config = {
            'iterations': 200,
            'games_per_iteration': 24,
            'mcts_simulations': 20,
            'batch_size': 512,
            'epochs': 8,
            'lr': 0.001,
            'hidden_size': 256,
            'arena_compare': 10,
            'use_bootstrap': True,
            'use_multiprocessing': True,
            'num_parallel_games': min(64, num_gpus * 4),
            'num_workers': min(num_cpus - 2, num_gpus * 10),
            'save_every_n_iters': 5,
            'update_threshold': 0.55
        }
    else:
        # Single GPU
        config = {
            'iterations': 200,
            'games_per_iteration': 16,
            'mcts_simulations': 15,
            'batch_size': 256,
            'epochs': 5,
            'lr': 0.001,
            'hidden_size': 256,
            'arena_compare': 8,
            'use_bootstrap': True,
            'use_multiprocessing': True,
            'num_parallel_games': 8,
            'num_workers': min(num_cpus - 2, 10),
            'save_every_n_iters': 5,
            'update_threshold': 0.55
        }
    
    print("üìã –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è:")
    print(f"   –ò—Ç–µ—Ä–∞—Ü–∏–π: {config['iterations']}")
    print(f"   –ò–≥—Ä –Ω–∞ –∏—Ç–µ—Ä–∞—Ü–∏—é: {config['games_per_iteration']}")
    print(f"   MCTS —Å–∏–º—É–ª—è—Ü–∏–π: {config['mcts_simulations']}")
    print(f"   Batch size: {config['batch_size']}")
    print(f"   Epochs: {config['epochs']}")
    print(f"   –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã—Ö –∏–≥—Ä: {config['num_parallel_games']}")
    print(f"   Workers: {config['num_workers']}")
    print(f"   Multiprocessing: {config['use_multiprocessing']}")
    print()
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø—É—Ç—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —á–µ–∫–ø–æ–π–Ω—Ç–æ–≤
    task_manager = AlphaZeroTaskManager()
    checkpoints_dir = os.path.join(task_manager.engine_dir, "models", "alphazero")
    os.makedirs(checkpoints_dir, exist_ok=True)
    
    print(f"üíæ –ß–µ–∫–ø–æ–π–Ω—Ç—ã –±—É–¥—É—Ç —Å–æ—Ö—Ä–∞–Ω—è—Ç—å—Å—è –≤: {checkpoints_dir}")
    print()
    
    try:
        # –ó–∞–ø—É—Å–∫–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ
        print("üöÄ –ó–∞–ø—É—Å–∫ AlphaZero training...")
        task_id = task_manager.start_training(config)
        print(f"‚úÖ –û–±—É—á–µ–Ω–∏–µ –∑–∞–ø—É—â–µ–Ω–æ! Task ID: {task_id}")
        print()
        print("=" * 70)
        print("  –û–ë–£–ß–ï–ù–ò–ï –ó–ê–ü–£–©–ï–ù–û")
        print("=" * 70)
        print()
        print("üìä –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞:")
        print(f"   - –°—Ç–∞—Ç—É—Å: curl http://localhost:8000/api/training/alphazero/sessions/{task_id}")
        print(f"   - –ß–µ–∫–ø–æ–π–Ω—Ç—ã: ls -lh {checkpoints_dir}")
        print()
        print("‚èπÔ∏è  –î–ª—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∏ –Ω–∞–∂–º–∏—Ç–µ Ctrl+C")
        print()
        
        # –ú–æ–Ω–∏—Ç–æ—Ä–∏–º –ø—Ä–æ–≥—Ä–µ—Å—Å
        last_iteration = 0
        while True:
            if stop_requested:
                print("\nüõë –ó–∞–ø—Ä–æ—Å –Ω–∞ –æ—Å—Ç–∞–Ω–æ–≤–∫—É –ø–æ–ª—É—á–µ–Ω...")
                task_manager.stop_task(task_id)
                break
            
            status = task_manager.get_status(task_id)
            if not status:
                print("‚ùå –ó–∞–¥–∞—á–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞!")
                break
            
            current_iter = status.get("current_iteration", 0)
            total_iter = status.get("total_iterations", config['iterations'])
            progress = status.get("progress", 0)
            task_status = status.get("status", "unknown")
            
            if current_iter != last_iteration:
                print(f"üìà –ò—Ç–µ—Ä–∞—Ü–∏—è {current_iter}/{total_iter} ({progress:.1f}%) - –°—Ç–∞—Ç—É—Å: {task_status}")
                last_iteration = current_iter
                
                # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ —á–µ–∫–ø–æ–π–Ω—Ç—ã
                if os.path.exists(checkpoints_dir):
                    checkpoints = [f for f in os.listdir(checkpoints_dir) if f.endswith('.pth.tar')]
                    if checkpoints:
                        latest = max(checkpoints, key=lambda f: os.path.getmtime(os.path.join(checkpoints_dir, f)))
                        size_mb = os.path.getsize(os.path.join(checkpoints_dir, latest)) / (1024 * 1024)
                        print(f"   üíæ –ü–æ—Å–ª–µ–¥–Ω–∏–π —á–µ–∫–ø–æ–π–Ω—Ç: {latest} ({size_mb:.2f} MB)")
            
            if task_status == "completed":
                print()
                print("=" * 70)
                print("  ‚úÖ –û–ë–£–ß–ï–ù–ò–ï –ó–ê–í–ï–†–®–ï–ù–û")
                print("=" * 70)
                print()
                print(f"üíæ –í—Å–µ —á–µ–∫–ø–æ–π–Ω—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {checkpoints_dir}")
                
                # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–µ —á–µ–∫–ø–æ–π–Ω—Ç—ã
                if os.path.exists(checkpoints_dir):
                    checkpoints = sorted([f for f in os.listdir(checkpoints_dir) if f.endswith('.pth.tar')])
                    print(f"\nüì¶ –í—Å–µ–≥–æ —á–µ–∫–ø–æ–π–Ω—Ç–æ–≤: {len(checkpoints)}")
                    if checkpoints:
                        print("   –ü–æ—Å–ª–µ–¥–Ω–∏–µ 5:")
                        for ckpt in checkpoints[-5:]:
                            size_mb = os.path.getsize(os.path.join(checkpoints_dir, ckpt)) / (1024 * 1024)
                            print(f"   - {ckpt} ({size_mb:.2f} MB)")
                break
            
            if task_status == "error":
                error = status.get("error", "Unknown error")
                print()
                print("=" * 70)
                print("  ‚ùå –û–®–ò–ë–ö–ê –û–ë–£–ß–ï–ù–ò–Ø")
                print("=" * 70)
                print(f"–û—à–∏–±–∫–∞: {error}")
                break
            
            time.sleep(5)  # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞–∂–¥—ã–µ 5 —Å–µ–∫—É–Ω–¥
        
    except KeyboardInterrupt:
        print("\n\n‚ö†Ô∏è  –ü—Ä–µ—Ä–≤–∞–Ω–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
        if 'task_id' in locals():
            task_manager.stop_task(task_id)
    except Exception as e:
        print(f"\n\n‚ùå –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
    
    print("\nüëã –ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ —Ä–∞–±–æ—Ç—ã...")

if __name__ == "__main__":
    main()
